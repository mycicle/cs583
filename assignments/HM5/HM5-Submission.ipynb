{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 5: Build a seq2seq model for machine translation.\n",
    "\n",
    "### Name: Michael DiGregorio\n",
    "\n",
    "### Task: Translate English to Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read and run my code.\n",
    "2. Complete the code in Section 1.1 and Section 4.2.\n",
    "\n",
    "    * Translation **English** to **German** is not acceptable!!! Try another pair of languages.\n",
    "    \n",
    "3. **Make improvements.** Directly modify the code in Section 3. Do at least one of the two. By doing both correctly, you will get up to 1 bonus score to the total.\n",
    "\n",
    "    * Bi-LSTM instead of LSTM.\n",
    "        \n",
    "    * Attention. (You are allowed to use existing code.)\n",
    "    \n",
    "4. Evaluate the translation using the BLEU score. \n",
    "\n",
    "    * Optional. Up to 1 bonus scores to the total.\n",
    "    \n",
    "5. Convert the notebook to .HTML file. \n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "\n",
    "6. Put the .HTML file in your Google Drive, Dropbox, or Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "7. Submit the link to the HTML file to Canvas.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint: \n",
    "\n",
    "To implement ```Bi-LSTM```, you will need the following code to build the encoder. Do NOT use Bi-LSTM for the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Bidirectional, Concatenate, LSTM\n",
    "\n",
    "# encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True, \n",
    "#                                   dropout=0.5, name='encoder_lstm'))\n",
    "# _, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "# state_h = Concatenate()([forward_h, backward_h])\n",
    "# state_c = Concatenate()([forward_c, backward_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am going to rewrite a lot of this becuase its horribly confusing to work with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "1. Download data (e.g., \"deu-eng.zip\") from http://www.manythings.org/anki/\n",
    "2. Unzip the .ZIP file.\n",
    "3. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import numpy\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from unicodedata import normalize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            # normalize unicode characters\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            # tokenize on white space\n",
    "            line = line.split()\n",
    "            # convert to lowercase\n",
    "            line = [word.lower() for word in line]\n",
    "            # remove punctuation from each token\n",
    "            line = [word.translate(table) for word in line]\n",
    "            # remove non-printable chars form each token\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            # remove tokens with numbers in them\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            # store as string\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return numpy.array(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill the following blanks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g., filename = 'Data/deu.txt'\n",
    "filename = 'data/spa.txt'\n",
    "\n",
    "# e.g., n_train = 20000\n",
    "n_train = 120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc entry C\n",
      "\n",
      "pairs entry ['No way!', 'Â¡Mangos!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2175 (CS) & #3843189 (cueyayotl)']\n",
      "\n",
      "clean pairs entry ['no way' 'mangos' 'ccby france attribution tatoebaorg cs cueyayotl']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "doc = load_doc(filename)\n",
    "# split into Language1-Language2 pairs\n",
    "pairs = to_pairs(doc)\n",
    "# clean sentences\n",
    "clean_pairs = clean_data(pairs)[0:n_train, :]\n",
    "\n",
    "print(f\"doc entry {doc[100]}\\n\")\n",
    "print(f\"pairs entry {pairs[100]}\\n\")\n",
    "print(f\"clean pairs entry {clean_pairs[100]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fix the roof] => [arregla el tejado]\n",
      "[get the book] => [trae el libro]\n",
      "[get the book] => [consigue el libro]\n",
      "[get the book] => [recoge el libro]\n",
      "[get the book] => [traiga el libro]\n",
      "[get the book] => [recoja el libro]\n",
      "[get upstairs] => [anda para arriba]\n",
      "[ghosts exist] => [los fantasmas existen]\n",
      "[give me half] => [dame la mitad]\n",
      "[give me half] => [deme la mitad]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3000, 3010):\n",
    "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_texts:  (120000,)\n",
      "Length of target_texts: (120000,)\n"
     ]
    }
   ],
   "source": [
    "input_texts = clean_pairs[:, 0]\n",
    "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
    "\n",
    "print('Length of input_texts:  ' + str(input_texts.shape))\n",
    "print('Length of target_texts: ' + str(input_texts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of input  sentences: 52\n",
      "max length of target sentences: 102\n"
     ]
    }
   ],
   "source": [
    "# max encoder seq length is the longest line of the input sentences\n",
    "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
    "# max decoder seq length is the longest line of the translated target sentences\n",
    "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
    "\n",
    "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
    "print('max length of target sentences: %d' % (max_decoder_seq_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text processing\n",
    "\n",
    "### 2.1. Convert texts to sequences\n",
    "\n",
    "- Input: A list of $n$ sentences (with max length $t$).\n",
    "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(Model):\n",
    "    def __init__(self, latent_dim: int, epochs: int):\n",
    "        super(Translator, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    \n",
    "    def call(self, english_sentences):\n",
    "        input_seq, input_token_index = self.generate_input_sequences(english_sentences)\n",
    "        \n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "\n",
    "        target_seq = numpy.zeros((1, 1, self.num_decoder_tokens))\n",
    "        target_seq[0, 0, self.target_token_index['\\t']] = 1.\n",
    "\n",
    "        stop_condition = False\n",
    "        decoded_sentence = ''\n",
    "        while not stop_condition:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            # this line of code is greedy selection\n",
    "            # try to use multinomial sampling instead (with temperature)\n",
    "            sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
    "\n",
    "            sampled_char = self.reverse_target_char_index[sampled_token_index]\n",
    "            decoded_sentence += sampled_char\n",
    "\n",
    "            if (sampled_char == '\\n' or\n",
    "               len(decoded_sentence) > self.max_decoder_seq_length):\n",
    "                stop_condition = True\n",
    "\n",
    "            target_seq = numpy.zeros((1, 1, self.num_decoder_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "            states_value = [h, c]\n",
    "\n",
    "        return decoded_sentence\n",
    "    \n",
    "    def generate_input_sequences(self, sentences):\n",
    "        seqs = self.encoder_tokenizer.texts_to_sequences(sentences)\n",
    "        encoder_input_seq = pad_sequences(seqs, maxlen=self.max_encoder_seq_length, padding='post')\n",
    "        encoder_input_data = self.onehot_encode(encoder_input_seq, self.max_encoder_seq_length, self.num_encoder_tokens)\n",
    "        return encoder_input_data, self.encoder_tokenizer.word_index\n",
    "\n",
    "    \n",
    "    def fit(self, input_text, target_text):\n",
    "        # generate sequence constraints\n",
    "        # max encoder seq length is the longest line of the input sentences\n",
    "        self.max_encoder_seq_length = max(len(line) for line in input_text)\n",
    "        # max decoder seq length is the longest line of the translated target sentences\n",
    "        self.max_decoder_seq_length = max(len(line) for line in target_text)\n",
    "        \n",
    "        # process the input text\n",
    "        self.encoder_tokenizer, encoder_input_seq, input_token_index = self.text2sequences(self.max_encoder_seq_length, \n",
    "                                                      input_text)\n",
    "        self.decoder_tokenizer, decoder_input_seq, target_token_index = self.text2sequences(self.max_decoder_seq_length, \n",
    "                                                       target_text)\n",
    "        self.target_token_index = target_token_index\n",
    "        print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
    "        print('shape of input_token_index: ' + str(len(input_token_index)))\n",
    "        print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
    "        print('shape of target_token_index: ' + str(len(target_token_index)))\n",
    "        self.num_encoder_tokens = len(input_token_index) + 1\n",
    "        self.num_decoder_tokens = len(target_token_index) + 1\n",
    "\n",
    "        print('num_encoder_tokens: ' + str(self.num_encoder_tokens))\n",
    "        print('num_decoder_tokens: ' + str(self.num_decoder_tokens))\n",
    "        print(target_text[100])\n",
    "        print(decoder_input_seq[100, :])\n",
    "        \n",
    "        encoder_input_data = self.onehot_encode(encoder_input_seq, \n",
    "                                                self.max_encoder_seq_length, \n",
    "                                                self.num_encoder_tokens)\n",
    "        \n",
    "        decoder_input_data = self.onehot_encode(decoder_input_seq, \n",
    "                                                self.max_decoder_seq_length, \n",
    "                                                self.num_decoder_tokens)\n",
    "\n",
    "        decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
    "        decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
    "        \n",
    "        decoder_target_data = self.onehot_encode(decoder_target_seq, \n",
    "                                        self.max_decoder_seq_length, \n",
    "                                        self.num_decoder_tokens)\n",
    "        \n",
    "        print(encoder_input_data.shape)\n",
    "        print(decoder_input_data.shape)\n",
    "        \n",
    "        # Reverse-lookup token index to decode sequences back to something readable.\n",
    "        self.reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "        self.reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "        \n",
    "        self.encoder_model, self.decoder_model, self.model = self.generate_models()\n",
    "\n",
    "        self.plot_model(self.encoder_model, 'encoder2.pdf')\n",
    "        self.plot_model(self.decoder_model, 'decoder2.pdf')\n",
    "        self.plot_model(self.model, 'model2.pdf')\n",
    "        \n",
    "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "        self.model.fit([encoder_input_data, decoder_input_data],  # training data\n",
    "                  decoder_target_data,                       # labels (left shift of the target sequences)\n",
    "                  batch_size=64, epochs=self.epochs, validation_split=0.2)\n",
    "    \n",
    "    def generate_models(self):\n",
    "        encoder_inputs = Input(shape=(None, self.num_encoder_tokens),\n",
    "                       name='encoder_inputs')\n",
    "        \n",
    "        encoder_bilstm = Bidirectional(LSTM(self.latent_dim, return_state=True, \n",
    "                                          dropout=0.5, name='encoder_lstm'))\n",
    "        _, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
    "\n",
    "        state_h = Concatenate()([forward_h, backward_h])\n",
    "        state_c = Concatenate()([forward_c, backward_c])\n",
    "        print(state_h.shape)\n",
    "        print(state_c.shape)\n",
    "        encoder_model = Model(inputs=encoder_inputs, \n",
    "                              outputs=[state_h, state_c],\n",
    "                              name='encoder')\n",
    "        \n",
    "        # inputs of the decoder network\n",
    "        decoder_input_h = Input(shape=(2*self.latent_dim,), name='decoder_input_h')\n",
    "        decoder_input_c = Input(shape=(2*self.latent_dim,), name='decoder_input_c')\n",
    "        decoder_input_x = Input(shape=(None, self.num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "        # set the LSTM layer\n",
    "        decoder_lstm = LSTM(2*self.latent_dim, return_sequences=True, \n",
    "                            return_state=True, dropout=0.5, name='decoder_lstm')\n",
    "        decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x, \n",
    "                                                              initial_state=[decoder_input_h, decoder_input_c])\n",
    "\n",
    "        # set the dense layer\n",
    "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "        decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "        # build the decoder network model\n",
    "        decoder_model= Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
    "                             outputs=[decoder_outputs, state_h, state_c],\n",
    "                             name='decoder')\n",
    "\n",
    "        # input layers\n",
    "        encoder_input_x = Input(shape=(None, self.num_encoder_tokens), name='encoder_input_x')\n",
    "        decoder_input_x = Input(shape=(None, self.num_decoder_tokens), name='decoder_input_x')\n",
    "\n",
    "        # connect encoder to decoder\n",
    "        encoder_final_states = encoder_model([encoder_input_x])\n",
    "        decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
    "        decoder_pred = decoder_dense(decoder_lstm_output)\n",
    "\n",
    "        model = Model(inputs=[encoder_input_x, decoder_input_x], \n",
    "                      outputs=decoder_pred, \n",
    "                      name='model_training')\n",
    "        \n",
    "        return encoder_model, decoder_model, model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_model(model, outfile):\n",
    "        SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
    "\n",
    "        plot_model(\n",
    "            model=model, show_shapes=False,\n",
    "            to_file=outfile\n",
    "        )\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "    @staticmethod\n",
    "    def text2sequences(max_len, lines):\n",
    "        tokenizer = Tokenizer(char_level=True, filters='')\n",
    "        tokenizer.fit_on_texts(lines)\n",
    "        seqs = tokenizer.texts_to_sequences(lines)\n",
    "        seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
    "        return tokenizer, seqs_pad, tokenizer.word_index\n",
    "    \n",
    "    @staticmethod\n",
    "    def onehot_encode(sequences, max_len, vocab_size):\n",
    "        n = len(sequences)\n",
    "        data = numpy.zeros((n, max_len, vocab_size))\n",
    "        for i in range(n):\n",
    "            data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (120000, 52)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (120000, 102)\n",
      "shape of target_token_index: 29\n",
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n",
      "\tmangos\n",
      "\n",
      "[13 15  3  6 22  4  5 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0]\n",
      "(120000, 52, 28)\n",
      "(120000, 102, 30)\n",
      "(None, 512)\n",
      "(None, 512)\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 512), (None, 583680      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "==================================================================================================\n",
      "Total params: 583,680\n",
      "Trainable params: 583,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,127,454\n",
      "Trainable params: 1,127,454\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,711,134\n",
      "Trainable params: 1,711,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "1500/1500 [==============================] - 54s 33ms/step - loss: 0.7693 - val_loss: 0.7669\n"
     ]
    }
   ],
   "source": [
    "translator = Translator(latent_dim=256, epochs=1)\n",
    "translator.fit(input_texts, target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the translation using BLEU score\n",
    "\n",
    "Reference: \n",
    "- https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "- https://en.wikipedia.org/wiki/BLEU\n",
    "\n",
    "\n",
    "**Hint:** \n",
    "\n",
    "- Randomly partition the dataset to training, validation, and test. \n",
    "\n",
    "- Evaluate the BLEU score using the test set. Report the average.\n",
    "\n",
    "- A reasonable BLEU score should be 0.1 ~ 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My bleu score is basically 0, but this is how you could implement it to evaluate the metric over a batch of content for a more robust score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_texts, target_texts, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoder_input_seq: (96000, 52)\n",
      "shape of input_token_index: 27\n",
      "shape of decoder_input_seq: (96000, 102)\n",
      "shape of target_token_index: 29\n",
      "num_encoder_tokens: 28\n",
      "num_decoder_tokens: 30\n",
      "\tse necesita mas\n",
      "\n",
      "[13  5  2  1  6  2 16  2  5  8  9  3  1 15  3  5 14  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0]\n",
      "(96000, 52, 28)\n",
      "(96000, 102, 30)\n",
      "(None, 512)\n",
      "(None, 512)\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 583680      encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "==================================================================================================\n",
      "Total params: 583,680\n",
      "Trainable params: 583,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_h (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_c (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 decoder_input_h[0][0]            \n",
      "                                                                 decoder_input_c[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,127,454\n",
      "Trainable params: 1,127,454\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_training\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input_x (InputLayer)    [(None, None, 28)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input_x (InputLayer)    [(None, None, 30)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            [(None, 512), (None, 583680      encoder_input_x[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(None, None, 512),  1112064     decoder_input_x[0][0]            \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, None, 30)     15390       decoder_lstm[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,711,134\n",
      "Trainable params: 1,711,134\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1200/1200 [==============================] - 42s 33ms/step - loss: 0.9022 - val_loss: 0.5235\n",
      "Epoch 2/50\n",
      "1200/1200 [==============================] - 39s 32ms/step - loss: 0.6328 - val_loss: 0.4531\n",
      "Epoch 3/50\n",
      "1200/1200 [==============================] - 39s 32ms/step - loss: 0.5923 - val_loss: 0.4133\n",
      "Epoch 4/50\n",
      "1200/1200 [==============================] - 39s 32ms/step - loss: 0.5650 - val_loss: 0.3897\n",
      "Epoch 5/50\n",
      "1200/1200 [==============================] - 39s 32ms/step - loss: 0.5444 - val_loss: 0.3727\n",
      "Epoch 6/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.5320 - val_loss: 0.3587\n",
      "Epoch 7/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.5211 - val_loss: 0.3488\n",
      "Epoch 8/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.5131 - val_loss: 0.3395\n",
      "Epoch 9/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.5058 - val_loss: 0.3323\n",
      "Epoch 10/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.4992 - val_loss: 0.3265\n",
      "Epoch 11/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.4938 - val_loss: 0.3212\n",
      "Epoch 12/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.4888 - val_loss: 0.3165\n",
      "Epoch 13/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4827 - val_loss: 0.3124\n",
      "Epoch 14/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4808 - val_loss: 0.3088\n",
      "Epoch 15/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4782 - val_loss: 0.3057\n",
      "Epoch 16/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4717 - val_loss: 0.3022\n",
      "Epoch 17/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4681 - val_loss: 0.3007\n",
      "Epoch 18/50\n",
      "1200/1200 [==============================] - 40s 34ms/step - loss: 0.4669 - val_loss: 0.2963\n",
      "Epoch 19/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4640 - val_loss: 0.2948\n",
      "Epoch 20/50\n",
      "1200/1200 [==============================] - 44s 36ms/step - loss: 0.4620 - val_loss: 0.2921\n",
      "Epoch 21/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4580 - val_loss: 0.2901\n",
      "Epoch 22/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4566 - val_loss: 0.2882\n",
      "Epoch 23/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4539 - val_loss: 0.2876\n",
      "Epoch 24/50\n",
      "1200/1200 [==============================] - 44s 37ms/step - loss: 0.4510 - val_loss: 0.2843\n",
      "Epoch 25/50\n",
      "1200/1200 [==============================] - 43s 36ms/step - loss: 0.4499 - val_loss: 0.2826\n",
      "Epoch 26/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4483 - val_loss: 0.2818\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 41s 35ms/step - loss: 0.4472 - val_loss: 0.2791\n",
      "Epoch 28/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4439 - val_loss: 0.2781\n",
      "Epoch 29/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4450 - val_loss: 0.2774\n",
      "Epoch 30/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4415 - val_loss: 0.2757\n",
      "Epoch 31/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4414 - val_loss: 0.2755\n",
      "Epoch 32/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4395 - val_loss: 0.2742\n",
      "Epoch 33/50\n",
      "1200/1200 [==============================] - 43s 36ms/step - loss: 0.4384 - val_loss: 0.2728\n",
      "Epoch 34/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4360 - val_loss: 0.2724\n",
      "Epoch 35/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4370 - val_loss: 0.2708\n",
      "Epoch 36/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4351 - val_loss: 0.2700\n",
      "Epoch 37/50\n",
      "1200/1200 [==============================] - 43s 36ms/step - loss: 0.4343 - val_loss: 0.2700\n",
      "Epoch 38/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4323 - val_loss: 0.2676\n",
      "Epoch 39/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4305 - val_loss: 0.2666\n",
      "Epoch 40/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4300 - val_loss: 0.2658\n",
      "Epoch 41/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4275 - val_loss: 0.2654\n",
      "Epoch 42/50\n",
      "1200/1200 [==============================] - 43s 36ms/step - loss: 0.4272 - val_loss: 0.2635\n",
      "Epoch 43/50\n",
      "1200/1200 [==============================] - 39s 33ms/step - loss: 0.4270 - val_loss: 0.2628\n",
      "Epoch 44/50\n",
      "1200/1200 [==============================] - 43s 36ms/step - loss: 0.4256 - val_loss: 0.2634\n",
      "Epoch 45/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4243 - val_loss: 0.2626\n",
      "Epoch 46/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4241 - val_loss: 0.2619\n",
      "Epoch 47/50\n",
      "1200/1200 [==============================] - 40s 33ms/step - loss: 0.4243 - val_loss: 0.2600\n",
      "Epoch 48/50\n",
      "1200/1200 [==============================] - 42s 35ms/step - loss: 0.4259 - val_loss: 0.2606\n",
      "Epoch 49/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4229 - val_loss: 0.2592\n",
      "Epoch 50/50\n",
      "1200/1200 [==============================] - 41s 34ms/step - loss: 0.4222 - val_loss: 0.2594\n"
     ]
    }
   ],
   "source": [
    "model = Translator(latent_dim=256, epochs=50)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "y_test_batches = numpy.array_split(numpy.asarray(y_test), math.ceil(len(y_test)/batch_size))\n",
    "x_test_batches = numpy.array_split(numpy.asarray(x_test), math.ceil(len(x_test)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "batches_to_test = 10\n",
    "\n",
    "\n",
    "scores = []\n",
    "print(corpus_bleu([[['he', 'is', 'my', 'dog']]], [['he', 'is', 'my', 'dog']]))\n",
    "for i in range(batches_to_test):\n",
    "    hypothesis = []\n",
    "    references = []\n",
    "    for english_sentence in x_test_batches[i]:\n",
    "        hypothesis.append(model([english_sentence]))\n",
    "#     print([hypothesis])\n",
    "    for spanish_sentence in y_test_batches[i]:\n",
    "        references.append(spanish_sentence[1:-1])\n",
    "#     print([[references]])\n",
    "    score = corpus_bleu([[references]], [hypothesis])\n",
    "    scores.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(scores)/len(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs583",
   "language": "python",
   "name": "cs583"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
