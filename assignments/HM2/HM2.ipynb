{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM2: Numerical Optimization for Logistic Regression.\n",
    "\n",
    "### Name: Michael DiGregorio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf)\n",
    "\n",
    "2. Read, complete, and run my code.\n",
    "\n",
    "3. **Implement mini-batch SGD** and evaluate the performance.\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM2/HM2.html\n",
    "\n",
    "\n",
    "## Grading criteria:\n",
    "\n",
    "1. When computing the ```gradient``` and ```objective function value``` using a batch of samples, use **matrix-vector multiplication** rather than a FOR LOOP of **vector-vector multiplications**.\n",
    "\n",
    "2. Plot ```objective function value``` against ```epochs```. In the plot, compare GD, SGD, and MB-SGD (with $b=8$ and $b=64$). The plot must look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.19190758 -0.12269459 -0.09711901 -0.05375944  0.01065632 -0.15573104\n",
      "   0.02467951 -0.18068711]]\n",
      "test std = \n",
      "[[0.87167522 0.80535323 0.86775558 1.04745464 1.05616325 0.98664325\n",
      "  0.94255181 0.95044027]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression model\n",
    "\n",
    "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.593757830624754\n",
      "Objective value at t=2 is 0.5521662400404361\n",
      "Objective value at t=3 is 0.5296888095322997\n",
      "Objective value at t=4 is 0.5156726448005342\n",
      "Objective value at t=5 is 0.5062093586919761\n",
      "Objective value at t=6 is 0.49950119533105863\n",
      "Objective value at t=7 is 0.4945879496410943\n",
      "Objective value at t=8 is 0.4909030090804414\n",
      "Objective value at t=9 is 0.48808844743189117\n",
      "Objective value at t=10 is 0.48590699168570245\n",
      "Objective value at t=11 is 0.48419564102806956\n",
      "Objective value at t=12 is 0.482839288608493\n",
      "Objective value at t=13 is 0.4817548267460104\n",
      "Objective value at t=14 is 0.48088113577642205\n",
      "Objective value at t=15 is 0.4801725561606777\n",
      "Objective value at t=16 is 0.47959451118827273\n",
      "Objective value at t=17 is 0.479120502814294\n",
      "Objective value at t=18 is 0.47873000866745047\n",
      "Objective value at t=19 is 0.47840698430234496\n",
      "Objective value at t=20 is 0.4781387801007629\n",
      "Objective value at t=21 is 0.4779153472422654\n",
      "Objective value at t=22 is 0.4777286483549482\n",
      "Objective value at t=23 is 0.47757221514164977\n",
      "Objective value at t=24 is 0.4774408129029529\n",
      "Objective value at t=25 is 0.477330183723393\n",
      "Objective value at t=26 is 0.4772368481719286\n",
      "Objective value at t=27 is 0.47715795096435176\n",
      "Objective value at t=28 is 0.47709113996031904\n",
      "Objective value at t=29 is 0.477034470653703\n",
      "Objective value at t=30 is 0.4769863303148214\n",
      "Objective value at t=31 is 0.47694537739372944\n",
      "Objective value at t=32 is 0.4769104928563945\n",
      "Objective value at t=33 is 0.47688074091116134\n",
      "Objective value at t=34 is 0.476855337168769\n",
      "Objective value at t=35 is 0.47683362271962454\n",
      "Objective value at t=36 is 0.47681504294574606\n",
      "Objective value at t=37 is 0.47679913013943737\n",
      "Objective value at t=38 is 0.4767854891964253\n",
      "Objective value at t=39 is 0.4767737858025052\n",
      "Objective value at t=40 is 0.47676373665046845\n",
      "Objective value at t=41 is 0.47675510131621895\n",
      "Objective value at t=42 is 0.47674767549546554\n",
      "Objective value at t=43 is 0.4767412853597106\n",
      "Objective value at t=44 is 0.4767357828358088\n",
      "Objective value at t=45 is 0.47673104164974117\n",
      "Objective value at t=46 is 0.4767269540044132\n",
      "Objective value at t=47 is 0.47672342778476806\n",
      "Objective value at t=48 is 0.47672038420247853\n",
      "Objective value at t=49 is 0.4767177558078818\n",
      "Objective value at t=50 is 0.4767154848093471\n",
      "Objective value at t=51 is 0.4767135216505081\n",
      "Objective value at t=52 is 0.4767118238041692\n",
      "Objective value at t=53 is 0.47671035474858925\n",
      "Objective value at t=54 is 0.4767090830975179\n",
      "Objective value at t=55 is 0.47670798186005403\n",
      "Objective value at t=56 is 0.47670702781026986\n",
      "Objective value at t=57 is 0.4767062009497755\n",
      "Objective value at t=58 is 0.47670548404907515\n",
      "Objective value at t=59 is 0.47670486225579967\n",
      "Objective value at t=60 is 0.4767043227597711\n",
      "Objective value at t=61 is 0.476703854506413\n",
      "Objective value at t=62 is 0.4767034479513325\n",
      "Objective value at t=63 is 0.4767030948499959\n",
      "Objective value at t=64 is 0.4767027880773499\n",
      "Objective value at t=65 is 0.4767025214730145\n",
      "Objective value at t=66 is 0.47670228970833256\n",
      "Objective value at t=67 is 0.4767020881721171\n",
      "Objective value at t=68 is 0.47670191287240476\n",
      "Objective value at t=69 is 0.47670176035192163\n",
      "Objective value at t=70 is 0.4767016276153091\n",
      "Objective value at t=71 is 0.47670151206643313\n",
      "Objective value at t=72 is 0.47670141145435607\n",
      "Objective value at t=73 is 0.47670132382674735\n",
      "Objective value at t=74 is 0.47670124748968773\n",
      "Objective value at t=75 is 0.4767011809729762\n",
      "Objective value at t=76 is 0.4767011230001683\n",
      "Objective value at t=77 is 0.47670107246269156\n",
      "Objective value at t=78 is 0.4767010283974718\n",
      "Objective value at t=79 is 0.47670098996758714\n",
      "Objective value at t=80 is 0.47670095644553173\n",
      "Objective value at t=81 is 0.476700927198732\n",
      "Objective value at t=82 is 0.47670090167700757\n",
      "Objective value at t=83 is 0.47670087940171096\n",
      "Objective value at t=84 is 0.47670085995631784\n",
      "Objective value at t=85 is 0.47670084297827225\n",
      "Objective value at t=86 is 0.47670082815191545\n",
      "Objective value at t=87 is 0.4767008152023533\n",
      "Objective value at t=88 is 0.4767008038901354\n",
      "Objective value at t=89 is 0.47670079400663723\n",
      "Objective value at t=90 is 0.4767007853700506\n",
      "Objective value at t=91 is 0.4767007778219029\n",
      "Objective value at t=92 is 0.476700771224032\n",
      "Objective value at t=93 is 0.47670076545595813\n",
      "Objective value at t=94 is 0.4767007604125997\n",
      "Objective value at t=95 is 0.4767007560022871\n",
      "Objective value at t=96 is 0.4767007521450359\n",
      "Objective value at t=97 is 0.4767007487710434\n",
      "Objective value at t=98 is 0.47670074581938227\n",
      "Objective value at t=99 is 0.4767007432368619\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5422296238268267\n",
      "Objective value at epoch t=1 is 0.5247950634997955\n",
      "Objective value at epoch t=2 is 0.5214661525233136\n",
      "Objective value at epoch t=3 is 0.5171922122799838\n",
      "Objective value at epoch t=4 is 0.5008567364468863\n",
      "Objective value at epoch t=5 is 0.5037462900855167\n",
      "Objective value at epoch t=6 is 0.5117011807746253\n",
      "Objective value at epoch t=7 is 0.5056068182786715\n",
      "Objective value at epoch t=8 is 0.503574671623053\n",
      "Objective value at epoch t=9 is 0.5003341288812156\n",
      "Objective value at epoch t=10 is 0.4975963245364247\n",
      "Objective value at epoch t=11 is 0.4920881179205713\n",
      "Objective value at epoch t=12 is 0.49463318919029203\n",
      "Objective value at epoch t=13 is 0.4885611216997165\n",
      "Objective value at epoch t=14 is 0.49281198779450464\n",
      "Objective value at epoch t=15 is 0.4876278219225548\n",
      "Objective value at epoch t=16 is 0.48837504927419406\n",
      "Objective value at epoch t=17 is 0.48753618264850784\n",
      "Objective value at epoch t=18 is 0.48593923017802415\n",
      "Objective value at epoch t=19 is 0.48537878016353214\n",
      "Objective value at epoch t=20 is 0.4855940271660441\n",
      "Objective value at epoch t=21 is 0.48366205659127026\n",
      "Objective value at epoch t=22 is 0.48388286068197556\n",
      "Objective value at epoch t=23 is 0.4827222045193132\n",
      "Objective value at epoch t=24 is 0.4822383824968356\n",
      "Objective value at epoch t=25 is 0.48172960099785705\n",
      "Objective value at epoch t=26 is 0.48154483350505073\n",
      "Objective value at epoch t=27 is 0.48075667480490536\n",
      "Objective value at epoch t=28 is 0.4804852767695332\n",
      "Objective value at epoch t=29 is 0.48015011797201057\n",
      "Objective value at epoch t=30 is 0.4795997982843162\n",
      "Objective value at epoch t=31 is 0.4795348498448777\n",
      "Objective value at epoch t=32 is 0.4791204280405551\n",
      "Objective value at epoch t=33 is 0.4789646560295585\n",
      "Objective value at epoch t=34 is 0.47873398079056234\n",
      "Objective value at epoch t=35 is 0.4785702416998717\n",
      "Objective value at epoch t=36 is 0.47834290303309024\n",
      "Objective value at epoch t=37 is 0.47821028893800915\n",
      "Objective value at epoch t=38 is 0.4780741238589206\n",
      "Objective value at epoch t=39 is 0.47791990934264594\n",
      "Objective value at epoch t=40 is 0.47781738984124067\n",
      "Objective value at epoch t=41 is 0.4777133503861357\n",
      "Objective value at epoch t=42 is 0.4776050502755681\n",
      "Objective value at epoch t=43 is 0.47752203630960033\n",
      "Objective value at epoch t=44 is 0.4774279887684504\n",
      "Objective value at epoch t=45 is 0.47736358372489285\n",
      "Objective value at epoch t=46 is 0.47729239600379714\n",
      "Objective value at epoch t=47 is 0.47724109033942186\n",
      "Objective value at epoch t=48 is 0.4771780485573201\n",
      "Objective value at epoch t=49 is 0.4771396126404045\n",
      "Objective value at epoch t=50 is 0.4770954649141167\n",
      "Objective value at epoch t=51 is 0.4770572384222871\n",
      "Objective value at epoch t=52 is 0.47702112090632565\n",
      "Objective value at epoch t=53 is 0.47698858751472495\n",
      "Objective value at epoch t=54 is 0.476960675473765\n",
      "Objective value at epoch t=55 is 0.4769349916037628\n",
      "Objective value at epoch t=56 is 0.47691154891124843\n",
      "Objective value at epoch t=57 is 0.47689019078761763\n",
      "Objective value at epoch t=58 is 0.4768718294367072\n",
      "Objective value at epoch t=59 is 0.4768547683953147\n",
      "Objective value at epoch t=60 is 0.4768395187033209\n",
      "Objective value at epoch t=61 is 0.47682557501878564\n",
      "Objective value at epoch t=62 is 0.4768131740713323\n",
      "Objective value at epoch t=63 is 0.4768020279651779\n",
      "Objective value at epoch t=64 is 0.47679195348094405\n",
      "Objective value at epoch t=65 is 0.476782837289496\n",
      "Objective value at epoch t=66 is 0.47677458814586693\n",
      "Objective value at epoch t=67 is 0.4767673802836446\n",
      "Objective value at epoch t=68 is 0.47676062431348465\n",
      "Objective value at epoch t=69 is 0.47675475701958653\n",
      "Objective value at epoch t=70 is 0.4767494675632638\n",
      "Objective value at epoch t=71 is 0.47674462872651074\n",
      "Objective value at epoch t=72 is 0.47674029577711013\n",
      "Objective value at epoch t=73 is 0.47673638757463455\n",
      "Objective value at epoch t=74 is 0.47673286068106097\n",
      "Objective value at epoch t=75 is 0.47672969087037903\n",
      "Objective value at epoch t=76 is 0.4767268136732848\n",
      "Objective value at epoch t=77 is 0.4767242865278384\n",
      "Objective value at epoch t=78 is 0.4767219787282916\n",
      "Objective value at epoch t=79 is 0.4767198971990495\n",
      "Objective value at epoch t=80 is 0.4767180262101037\n",
      "Objective value at epoch t=81 is 0.47671634414695374\n",
      "Objective value at epoch t=82 is 0.4767148284875626\n",
      "Objective value at epoch t=83 is 0.4767134615160974\n",
      "Objective value at epoch t=84 is 0.47671223455766254\n",
      "Objective value at epoch t=85 is 0.4767111292686166\n",
      "Objective value at epoch t=86 is 0.47671013637567405\n",
      "Objective value at epoch t=87 is 0.4767092429324166\n",
      "Objective value at epoch t=88 is 0.4767084373074054\n",
      "Objective value at epoch t=89 is 0.4767077122187633\n",
      "Objective value at epoch t=90 is 0.47670705991170975\n",
      "Objective value at epoch t=91 is 0.4767064719035769\n",
      "Objective value at epoch t=92 is 0.4767059440759846\n",
      "Objective value at epoch t=93 is 0.4767054682213308\n",
      "Objective value at epoch t=94 is 0.4767050401293713\n",
      "Objective value at epoch t=95 is 0.47670465489049396\n",
      "Objective value at epoch t=96 is 0.4767043081196188\n",
      "Objective value at epoch t=97 is 0.476703995965513\n",
      "Objective value at epoch t=98 is 0.4767037152144157\n",
      "Objective value at epoch t=99 is 0.47670346231313826\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare GD with SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-9b8d8f4cdfb5>:9: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:10: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:11: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xlabel('Epochs', FontSize=20)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:12: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.ylabel('Objective Value', FontSize=20)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:13: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xticks(FontSize=16)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:14: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.yticks(FontSize=16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1], ['GD', 'SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = numpy.dot(X, w)\n",
    "    f = numpy.sign(xw)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error is 0.2140625\n"
     ]
    }
   ],
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = numpy.abs(f_train - y_train) / 2\n",
    "error_train = numpy.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification error is 0.2265625\n"
     ]
    }
   ],
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = numpy.abs(f_test - y_test) / 2\n",
    "error_test = numpy.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mini-batch SGD (fill the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?]## 6.1. Compute the objective $Q_I$ and its gradient using a batch of samples\n",
    "\n",
    "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of stochastic_objective_gradient\n",
    "    # Use matrix-vector multiplication; do not use FOR LOOP of vector-vector multiplications\n",
    "    \n",
    "    # calculate the gradient\n",
    "#     print(f\"B: {b}\")\n",
    "#     print(f\"Shape of W: {w.shape}\")\n",
    "#     print(f\"Shape of Xi: {xi.shape}\")\n",
    "#     print(f\"Shape of Yi: {yi.shape}\")\n",
    "#     Calculate yi * xi\n",
    "    print(\"First three elements of yi\")\n",
    "    print(yi[:10, ...])\n",
    "    print(\"First three rows of xi\")\n",
    "    print(xi[:10, ...])\n",
    "    yx_mat: numpy.ndarray = numpy.multiply(yi, xi) # b-by-d matrix\n",
    "    print(\"First three rows of yx_mat\")\n",
    "    print(yx_mat[:10, ...])\n",
    "    yx: numpy.ndarray = numpy.sum(yx_mat, axis=0) # 1-by-d matrix\n",
    "    print(\"a supposedly 1-by-d yx\")\n",
    "    print(yx)\n",
    "#     print(f\"Shape of yx: {yx.shape}\")\n",
    "    yxw: numpy.ndarray = numpy.dot(yx, w)\n",
    "    print(\"The supposedly scalar yxw\")\n",
    "    print(yxw)\n",
    "    den: numpy.ndarray = 1 + numpy.exp(yxw)\n",
    "    print(\"The supposedly scalar denominator\")\n",
    "    print(den)\n",
    "    subgradient: numpy.ndarray = (1/b) * numpy.divide(-yx, den)\n",
    "    print(\"The supposedly 1-by-d subgradient\")\n",
    "    print(subgradient)\n",
    "    reg: numpy.ndarray = numpy.multiply(lam, w)\n",
    "    g = subgradient.reshape((d, 1)) + reg\n",
    "    print(\"The supposedly d-by-1 gradient\")\n",
    "    print(g)\n",
    "#     print(f\"Shape of yxw: {yxw.shape}\")\n",
    "\n",
    "#     print(f\"Shape of den: {den.shape}\")\n",
    "    \n",
    "#     print(f\"Shape of subgrad_matrix: {subgrad_matrix.shape}\")\n",
    "\n",
    "#     print(f\"Shape of subgrad : {subgrad.shape}\")\n",
    "\n",
    "#     print(f\"Shape of gradient: {g.shape}\")\n",
    "    \n",
    "    # calculate the objective function\n",
    "    \n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Implement mini-batch SGD\n",
    "\n",
    "Hints:\n",
    "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
    "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_stochastic_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch SGD for solving logistic regression\n",
    "# Inumpyuts:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def mb_sgd(x, y, lam, b, stepsize, max_epoch=100, w=None):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of sgd\n",
    "    # Record one objective value per epoch (not per iteration!)\n",
    "    n, d = x.shape\n",
    "    objvals: numpy.ndarray = numpy.zeros((max_epoch))\n",
    "    if n % b != 0:\n",
    "        raise ValueError(\"Dataset must be evenly divisible into batches. Invalid batch length\")\n",
    "        \n",
    "    if w is None:\n",
    "        w = numpy.random.randn(d, 1) # uniform random initialization\n",
    "    \n",
    "\n",
    "    \n",
    "    num_batches: int = n // b\n",
    "    objval = 0 # accumulate the objective values\n",
    "    for e in range(max_epoch):\n",
    "        rand_indices: numpy.ndarray = numpy.random.permutation(n)\n",
    "        x_rand: numpy.ndarray = x[rand_indices, ...]\n",
    "        y_rand: numpy.ndarray = y[rand_indices, ...]\n",
    "            \n",
    "        objval = 0 # accumulate objective values\n",
    "        for i in range(num_batches):\n",
    "            start: int = b*i\n",
    "            end: int = start + b\n",
    "            obj, g = mb_stochastic_objective_gradient(w, x[start:end, ...], y[start:end, ...], lam, b)\n",
    "            objval += obj\n",
    "            w -= stepsize*g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= num_batches\n",
    "        objvals[e] = objval\n",
    "        print(f'Objective value at epoch e={str(e)} is {str(objval)}')\n",
    "         \n",
    "        \n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Run MB-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three elements of yi\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]]\n",
      "First three rows of xi\n",
      "[[ 0.30495528 -0.01724279  0.13044183  0.14685024  0.28404983 -0.76075701\n",
      "  -0.67470565 -0.3042734   1.        ]\n",
      " [-0.86198868 -0.95965887 -0.37612838 -0.16938177 -0.18055477 -0.90029469\n",
      "   2.38613293 -0.7272425   1.        ]\n",
      " [ 0.30495528  2.04999246 -0.27481434  0.77931424  2.15123433 -0.12649542\n",
      "   0.33659781 -0.38886722  1.        ]\n",
      " [-0.57025269  0.74277017 -3.51686372 -1.30781697 -0.69775611 -0.59584912\n",
      "  -0.68966576 -0.47346104  1.        ]\n",
      " [-0.57025269 -0.95965887 -0.47744243 -1.30781697 -0.69775611 -1.1032584\n",
      "  -0.83627485 -0.7272425   1.        ]\n",
      " [-0.2785167  -0.26044694 -0.98401264 -0.67535297  0.04736447 -0.34214449\n",
      "   0.46525476 -0.7272425   1.        ]\n",
      " [-0.2785167   0.19556084  0.13044183  0.27334304  0.96780753  0.02572749\n",
      "   0.23486906 -0.55805486  1.        ]\n",
      " [ 0.30495528  0.65156861  0.43438396 -1.30781697 -0.69775611  1.62406644\n",
      "  -0.83926687  1.13382155  1.        ]]\n",
      "First three rows of yx_mat\n",
      "[[ 0.30495528 -0.01724279  0.13044183  0.14685024  0.28404983 -0.76075701\n",
      "  -0.67470565 -0.3042734   1.        ]\n",
      " [-0.86198868 -0.95965887 -0.37612838 -0.16938177 -0.18055477 -0.90029469\n",
      "   2.38613293 -0.7272425   1.        ]\n",
      " [-0.30495528 -2.04999246  0.27481434 -0.77931424 -2.15123433  0.12649542\n",
      "  -0.33659781  0.38886722 -1.        ]\n",
      " [ 0.57025269 -0.74277017  3.51686372  1.30781697  0.69775611  0.59584912\n",
      "   0.68966576  0.47346104 -1.        ]\n",
      " [-0.57025269 -0.95965887 -0.47744243 -1.30781697 -0.69775611 -1.1032584\n",
      "  -0.83627485 -0.7272425   1.        ]\n",
      " [-0.2785167  -0.26044694 -0.98401264 -0.67535297  0.04736447 -0.34214449\n",
      "   0.46525476 -0.7272425   1.        ]\n",
      " [ 0.2785167  -0.19556084 -0.13044183 -0.27334304 -0.96780753 -0.02572749\n",
      "  -0.23486906  0.55805486 -1.        ]\n",
      " [ 0.30495528  0.65156861  0.43438396 -1.30781697 -0.69775611  1.62406644\n",
      "  -0.83926687  1.13382155  1.        ]]\n",
      "a supposedly 1-by-d yx\n",
      "[[-0.55703341 -4.53376233  2.38847856 -3.05835875 -3.66593845 -0.78577108\n",
      "   0.61933922  0.06820377  2.        ]]\n",
      "The supposedly scalar yxw\n",
      "[[3.96943367]]\n",
      "The supposedly scalar denominator\n",
      "[[53.95453235]]\n",
      "The supposedly 1-by-d subgradient\n",
      "[[ 0.00129052  0.01050366 -0.00553354  0.0070855   0.00849312  0.00182045\n",
      "  -0.00143486 -0.00015801 -0.00463353]]\n",
      "The supposedly d-by-1 gradient\n",
      "[[ 0.00129069]\n",
      " [ 0.01050419]\n",
      " [-0.00553219]\n",
      " [ 0.00708476]\n",
      " [ 0.00849235]\n",
      " [ 0.00182189]\n",
      " [-0.00143553]\n",
      " [-0.00015806]\n",
      " [-0.0046337 ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-25133bf6d862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstepsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;31m# you must tune this parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjvals_mbsgd8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-cd8cada06601>\u001b[0m in \u001b[0;36mmb_sgd\u001b[0;34m(x, y, lam, b, stepsize, max_epoch, w)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb_stochastic_objective_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mobjval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-3fe0721170d8>\u001b[0m in \u001b[0;36mmb_stochastic_objective_gradient\u001b[0;34m(w, xi, yi, lam, b)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'obj' is not defined"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd8 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch e=0 is [[0.95446353]]\n",
      "Objective value at epoch e=1 is [[1.08502878]]\n",
      "Objective value at epoch e=2 is [[1.22683486]]\n",
      "Objective value at epoch e=3 is [[1.37660012]]\n",
      "Objective value at epoch e=4 is [[1.53126752]]\n",
      "Objective value at epoch e=5 is [[1.68799677]]\n",
      "Objective value at epoch e=6 is [[1.84417124]]\n",
      "Objective value at epoch e=7 is [[1.99747738]]\n",
      "Objective value at epoch e=8 is [[2.14599989]]\n",
      "Objective value at epoch e=9 is [[2.28826328]]\n",
      "Objective value at epoch e=10 is [[2.42321026]]\n",
      "Objective value at epoch e=11 is [[2.55015229]]\n",
      "Objective value at epoch e=12 is [[2.66871961]]\n",
      "Objective value at epoch e=13 is [[2.77880897]]\n",
      "Objective value at epoch e=14 is [[2.88052508]]\n",
      "Objective value at epoch e=15 is [[2.97412344]]\n",
      "Objective value at epoch e=16 is [[3.05996259]]\n",
      "Objective value at epoch e=17 is [[3.13846699]]\n",
      "Objective value at epoch e=18 is [[3.21009854]]\n",
      "Objective value at epoch e=19 is [[3.27533488]]\n",
      "Objective value at epoch e=20 is [[3.33465341]]\n",
      "Objective value at epoch e=21 is [[3.38852005]]\n",
      "Objective value at epoch e=22 is [[3.43738174]]\n",
      "Objective value at epoch e=23 is [[3.48166188]]\n",
      "Objective value at epoch e=24 is [[3.52175782]]\n",
      "Objective value at epoch e=25 is [[3.55803978]]\n",
      "Objective value at epoch e=26 is [[3.59085078]]\n",
      "Objective value at epoch e=27 is [[3.6205073]]\n",
      "Objective value at epoch e=28 is [[3.64730025]]\n",
      "Objective value at epoch e=29 is [[3.67149628]]\n",
      "Objective value at epoch e=30 is [[3.69333924]]\n",
      "Objective value at epoch e=31 is [[3.71305168]]\n",
      "Objective value at epoch e=32 is [[3.73083636]]\n",
      "Objective value at epoch e=33 is [[3.74687775]]\n",
      "Objective value at epoch e=34 is [[3.76134346]]\n",
      "Objective value at epoch e=35 is [[3.77438563]]\n",
      "Objective value at epoch e=36 is [[3.78614224]]\n",
      "Objective value at epoch e=37 is [[3.79673828]]\n",
      "Objective value at epoch e=38 is [[3.80628695]]\n",
      "Objective value at epoch e=39 is [[3.81489065]]\n",
      "Objective value at epoch e=40 is [[3.822642]]\n",
      "Objective value at epoch e=41 is [[3.8296247]]\n",
      "Objective value at epoch e=42 is [[3.8359144]]\n",
      "Objective value at epoch e=43 is [[3.84157938]]\n",
      "Objective value at epoch e=44 is [[3.84668132]]\n",
      "Objective value at epoch e=45 is [[3.85127586]]\n",
      "Objective value at epoch e=46 is [[3.85541321]]\n",
      "Objective value at epoch e=47 is [[3.85913865]]\n",
      "Objective value at epoch e=48 is [[3.86249304]]\n",
      "Objective value at epoch e=49 is [[3.86551319]]\n",
      "Objective value at epoch e=50 is [[3.8682323]]\n",
      "Objective value at epoch e=51 is [[3.87068029]]\n",
      "Objective value at epoch e=52 is [[3.87288412]]\n",
      "Objective value at epoch e=53 is [[3.87486809]]\n",
      "Objective value at epoch e=54 is [[3.87665408]]\n",
      "Objective value at epoch e=55 is [[3.87826181]]\n",
      "Objective value at epoch e=56 is [[3.87970904]]\n",
      "Objective value at epoch e=57 is [[3.88101177]]\n",
      "Objective value at epoch e=58 is [[3.88218441]]\n",
      "Objective value at epoch e=59 is [[3.88323993]]\n",
      "Objective value at epoch e=60 is [[3.88419002]]\n",
      "Objective value at epoch e=61 is [[3.88504519]]\n",
      "Objective value at epoch e=62 is [[3.88581493]]\n",
      "Objective value at epoch e=63 is [[3.88650775]]\n",
      "Objective value at epoch e=64 is [[3.88713134]]\n",
      "Objective value at epoch e=65 is [[3.88769262]]\n",
      "Objective value at epoch e=66 is [[3.8881978]]\n",
      "Objective value at epoch e=67 is [[3.88865249]]\n",
      "Objective value at epoch e=68 is [[3.88906173]]\n",
      "Objective value at epoch e=69 is [[3.88943007]]\n",
      "Objective value at epoch e=70 is [[3.88976159]]\n",
      "Objective value at epoch e=71 is [[3.89005996]]\n",
      "Objective value at epoch e=72 is [[3.89032851]]\n",
      "Objective value at epoch e=73 is [[3.89057021]]\n",
      "Objective value at epoch e=74 is [[3.89078775]]\n",
      "Objective value at epoch e=75 is [[3.89098354]]\n",
      "Objective value at epoch e=76 is [[3.89115976]]\n",
      "Objective value at epoch e=77 is [[3.89131835]]\n",
      "Objective value at epoch e=78 is [[3.89146109]]\n",
      "Objective value at epoch e=79 is [[3.89158956]]\n",
      "Objective value at epoch e=80 is [[3.89170518]]\n",
      "Objective value at epoch e=81 is [[3.89180924]]\n",
      "Objective value at epoch e=82 is [[3.8919029]]\n",
      "Objective value at epoch e=83 is [[3.89198719]]\n",
      "Objective value at epoch e=84 is [[3.89206305]]\n",
      "Objective value at epoch e=85 is [[3.89213133]]\n",
      "Objective value at epoch e=86 is [[3.89219278]]\n",
      "Objective value at epoch e=87 is [[3.89224809]]\n",
      "Objective value at epoch e=88 is [[3.89229786]]\n",
      "Objective value at epoch e=89 is [[3.89234266]]\n",
      "Objective value at epoch e=90 is [[3.89238298]]\n",
      "Objective value at epoch e=91 is [[3.89241927]]\n",
      "Objective value at epoch e=92 is [[3.89245193]]\n",
      "Objective value at epoch e=93 is [[3.89248132]]\n",
      "Objective value at epoch e=94 is [[3.89250777]]\n",
      "Objective value at epoch e=95 is [[3.89253158]]\n",
      "Objective value at epoch e=96 is [[3.89255301]]\n",
      "Objective value at epoch e=97 is [[3.89257229]]\n",
      "Objective value at epoch e=98 is [[3.89258965]]\n",
      "Objective value at epoch e=99 is [[3.89260527]]\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=64\n",
    "lam = 1E-6 # do not change\n",
    "b = 64 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd64 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot and compare GD, SGD, and MB-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to compare the following algorithms:\n",
    "\n",
    "- Gradient descent (GD)\n",
    "\n",
    "- SGD\n",
    "\n",
    "- MB-SGD with b=8\n",
    "\n",
    "- MB-SGD with b=64\n",
    "\n",
    "Follow the code in Section 4 to plot ```objective function value``` against ```epochs```. There should be four curves in the plot; each curve corresponds to one algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Logistic regression with $\\ell_2$-norm regularization is a strongly convex optimization problem. All the algorithms will converge to the same solution. **In the end, the ``objective function value`` of the 4 algorithms will be the same. If not the same, your implementation must be wrong. Do NOT submit wrong code and wrong result!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-e8438afdc3ae>:5: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line0, = plt.plot(epochs_mbsgd8, objvals_mbsgd8, '--b', LineWidth=4)\n",
      "<ipython-input-43-e8438afdc3ae>:6: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line1, = plt.plot(epochs_mbsgd64, objvals_mbsgd64, '--r', LineWidth=2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6, 4))\n",
    "epochs_mbsgd8 = range(len(objvals_mbsgd8))\n",
    "epochs_mbsgd64 = range(len(objvals_mbsgd64))\n",
    "\n",
    "line0, = plt.plot(epochs_mbsgd8, objvals_mbsgd8, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_mbsgd64, objvals_mbsgd64, '--r', LineWidth=2)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
